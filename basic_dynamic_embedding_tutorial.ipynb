{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59145d2e",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439245e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 19:03:44.646238: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-16 19:03:44.646277: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:dynamic_embedding.GraphKeys has already been deprecated. The Variable will not be added to collections because it does not actully own any value, but only a holder of tables, which may lead to import_meta_graph failed since non-valued object has been added to collection. If you need to use `tf.compat.v1.train.Saver` and access all Variables from collection, you could manually add it to the collection by tf.compat.v1.add_to_collections(names, var) instead.\n",
      "2.8.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_recommenders_addons as tfra\n",
    "import tensorflow_recommenders_addons.dynamic_embedding as de\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab3e40",
   "metadata": {},
   "source": [
    "## Checking how the table size changes with insert\n",
    "\n",
    "# Notes:\n",
    "\n",
    "* `de.embedding_lookup()` function does not insert keys into the CuckooHashTable. It simply returns a dynamically created set of defualts using a given initializer. \n",
    "  * If you want to see the table actually being updated, you'd need to trigger backpropagation through the returned variable of `de.embedding_lookup()`.\n",
    "\n",
    "* `DynamicEmbeddingOptimizer()` calls `var.update_op()`, which will [insert the keys](https://github.com/tensorflow/recommenders-addons/blob/r0.5/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_ops.py#L365)\n",
    "  * This is called after applying gradients to variables as shown [here](https://github.com/tensorflow/recommenders-addons/blob/r0.5/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_optimizer.py#L139)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92bcfbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 19:04:02.198324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-16 19:04:02.198373: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-16 19:04:02.485289: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:279] HashTable on CPU is created on default mode: K=l, V=f, init_size=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.tables[0].size(): 0\n",
      "lookup: TensorShape(None)\n",
      "a_lookup.shape: (10, 128)\n",
      "w.tables[0].size(): 0\n",
      "lookup: TensorShape(None)\n",
      "a_lookup.shape: (5, 128)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# source: https://github.com/tensorflow/recommenders-addons/blob/master/tensorflow_recommenders_addons/dynamic_embedding/python/ops/dynamic_embedding_variable.py\n",
    "\n",
    "w = de.get_variable(\n",
    "        name=\"dynamic_embeddings\", initializer=tf.random_normal_initializer(), dim=128, init_size=1\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def lookup(w, ids):\n",
    "    lookup =  de.embedding_lookup(params=w, ids=ids)\n",
    "    tf.print(\"w.tables[0].size():\", w.tables[0].size())\n",
    "    tf.print(\"lookup:\", lookup.shape)\n",
    "    return lookup\n",
    "\n",
    "a = tf.constant(list(range(10)), dtype=tf.int64)\n",
    "b = tf.constant(list(range(8, 13)), dtype=tf.int64)\n",
    "\n",
    "a_lookup = lookup(w, a)\n",
    "print(f\"a_lookup.shape: {a_lookup.shape}\")\n",
    "b_lookup = lookup(w, b)\n",
    "print(f\"a_lookup.shape: {b_lookup.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48bf97a",
   "metadata": {},
   "source": [
    "## Updating the underneath `CuckooHashTable`\n",
    "\n",
    "Underneath this is doing something like,\n",
    "\n",
    "```\n",
    "keys_tensor = tf.constant(['a', 'b', 'c'])\n",
    "vals_tensor = tf.constant([7, 8, 9], dtype=tf.int64)\n",
    "input_tensor = tf.constant(['a', 'f'])\n",
    "\n",
    "tablel = tfra.dynamic_embedding.CuckooHashTable(\n",
    "    key_dtype=tf.string,\n",
    "    value_dtype=tf.int64,\n",
    "    default_value=[0]\n",
    ")\n",
    "table.insert(keys_tensor, vals_tensor)\n",
    "table.lookup(input_tensor).numpy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce2f318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([False False False False False False False False False False], shape=(10,), dtype=bool)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor([ True  True False False False], shape=(5,), dtype=bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 19:04:07.087856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-16 19:04:07.087922: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-16 19:04:07.089398: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:279] HashTable on CPU is created on default mode: K=l, V=f, init_size=1\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "w_dummy = de.get_variable(\n",
    "        name=\"dynamic_embeddings\", initializer=tf.random_normal_initializer(), dim=128, init_size=1\n",
    "    )\n",
    "\n",
    "a = tf.constant(list(range(10)), dtype=tf.int64)\n",
    "b = tf.constant(list(range(8, 13)), dtype=tf.int64)\n",
    "\n",
    "a_lookup, keys_exists = w_dummy.lookup(a, return_exists=True)\n",
    "print(keys_exists)\n",
    "print(w.size())\n",
    "w_dummy.upsert(a, a_lookup)\n",
    "print(w.size()) \n",
    "b_lookup, keys_exists = w_dummy.lookup(b, return_exists=True)\n",
    "print(keys_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cdffc2",
   "metadata": {},
   "source": [
    "## Using a RestrictPolicy to reduce the size of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b451e66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10, shape=(), dtype=int64)\n",
      "tf.Tensor(13, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 19:07:24.694006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-16 19:07:24.694061: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-16 19:07:24.695491: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:157] HashTable on CPU is created on optimized mode: K=l, V=i, DIM=1, init_size=1\n",
      "2023-03-16 19:07:24.696632: I ./tensorflow_recommenders_addons/dynamic_embedding/core/kernels/lookup_impl/lookup_table_op_cpu.h:279] HashTable on CPU is created on default mode: K=l, V=f, init_size=1\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "w_dummy = de.get_variable(\n",
    "    name=\"dynamic_embeddings\", \n",
    "    initializer=tf.random_normal_initializer(), \n",
    "    dim=128, \n",
    "    init_size=1, \n",
    "    restrict_policy=de.FrequencyRestrictPolicy\n",
    ")\n",
    "\n",
    "\n",
    "a = tf.constant(list(range(10)), dtype=tf.int64)\n",
    "b = tf.constant(list(range(8, 13)), dtype=tf.int64)\n",
    "\n",
    "a_lookup, keys_exists = w_dummy.lookup(a, return_exists=True)\n",
    "w_dummy.upsert(a, a_lookup)\n",
    "w_dummy.restrict_policy.apply_update(a)\n",
    "print(w_dummy.size()) \n",
    "\n",
    "b_lookup, keys_exists = w_dummy.lookup(b, return_exists=True)\n",
    "w_dummy.upsert(b, b_lookup)\n",
    "w_dummy.restrict_policy.apply_update(b)\n",
    "print(w_dummy.size()) \n",
    "\n",
    "#print(w_dummy.restrict_policy.status)\n",
    "\n",
    "# Reduce the size of the table\n",
    "w_dummy.restrict(5)\n",
    "print(w_dummy.size())\n",
    "#w_dummy.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db554e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
